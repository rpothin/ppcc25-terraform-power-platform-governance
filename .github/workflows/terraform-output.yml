# Terraform Output Workflow for Power Platform Governance
# This workflow executes a Terraform configuration with data sources and exports the output to JSON/YAML
# Designed for migration scenarios to understand current Power Platform state

name: Terraform Output

# Prevent concurrent Terraform operations on same configuration
concurrency:
  group: terraform-${{ github.event.inputs.configuration || 'default' }}-output-${{ github.ref }}
  cancel-in-progress: false  # Don't cancel running Terraform operations

# Trigger: Manual workflow dispatch only
# Users can select which configuration to execute for output
on:
  workflow_dispatch:
    inputs:
      configuration:
        description: 'Terraform configuration to execute and export output (data source only configurations)'
        required: true
        type: choice
        options:
          - '01-dlp-policies'
      export_format:
        description: 'Output format for exported data'
        required: true
        type: choice
        options:
          - 'json'
          - 'yaml'
        default: 'json'
      include_metadata:
        description: 'Include execution metadata in output'
        required: true
        type: boolean
        default: true

# Dynamic run name showing the configuration and output format
run-name: ðŸ” Terraform Output for ${{ github.event.inputs.configuration }} (${{ github.event.inputs.export_format }}) by @${{ github.actor }}

# Required permissions for OIDC authentication with Azure and Power Platform
permissions:
  id-token: write   # Required for GitHub OIDC token generation
  contents: write   # Required for repository checkout and committing exported files

jobs:
  # Job 1: Execute Terraform Output using Reusable Workflow
  # Uses the standardized reusable-terraform-base workflow for consistent operation
  terraform-output:
    name: ðŸ” Extract Terraform Output
    uses: ./.github/workflows/reusable-terraform-base.yml
    with:
      operation: 'output'
      configuration: ${{ github.event.inputs.configuration }}
      additional-options: '-json'  # Always get JSON output for processing
      state-key-override: 'output-${{ github.event.inputs.configuration }}.tfstate'
      timeout-minutes: 10
      environment-name: 'production'
    secrets: inherit
  
  # Job 2: Process and Format Output
  # Handles format conversion, metadata inclusion, and file commitment
  process-and-commit-output:
    name: ðŸ“„ Process and Commit Output Files
    runs-on: ubuntu-latest
    timeout-minutes: 5
    needs: terraform-output
    if: needs.terraform-output.outputs.operation-successful == 'true'
    
    # Output values that can be used by dependent workflows
    outputs:
      output-generated: ${{ steps.process-output.outputs.output-generated }}
      output-filename: ${{ steps.process-output.outputs.output-filename }}
      configuration: ${{ github.event.inputs.configuration }}
      output-metadata: ${{ steps.process-output.outputs.output-metadata }}
    
    steps:
      # Step 1: Checkout repository for file operations
      - name: Checkout Repository for Processing
        uses: actions/checkout@v4
        with:
          fetch-depth: 0  # Full history for proper commit operations
      
      # Step 2: Download Terraform output artifact from reusable workflow
      - name: Download Terraform Output Artifact
        uses: actions/download-artifact@v4
        with:
          name: terraform-output-${{ github.event.inputs.configuration }}-default
          path: terraform-artifacts
      
      # Step 3: Setup yq for YAML processing (if needed)
      - name: Setup yq for YAML Processing
        if: github.event.inputs.export_format == 'yaml'
        uses: mikefarah/yq@v4.46.1
      
      # Step 4: Process Terraform Output
      - name: Process and Format Terraform Output
        id: process-output
        run: |
          config="${{ github.event.inputs.configuration }}"
          export_format="${{ github.event.inputs.export_format }}"
          include_metadata="${{ github.event.inputs.include_metadata }}"
          
          echo "::notice title=Processing Output::ðŸ”„ Processing Terraform output for configuration: $config"
          echo "::notice title=Format::ðŸ“„ Export format: $export_format"
          echo "::notice title=Metadata::ðŸ“Š Include metadata: $include_metadata"
          
          # Check what the reusable workflow provided
          tf_output_status='${{ needs.terraform-output.outputs.terraform-output }}'
          echo "::debug::Terraform output status: $tf_output_status"
          
          # Find the artifact file (JSON takes precedence over text)
          if [ -f "terraform-artifacts/terraform-output-artifact.json" ]; then
            artifact_file="terraform-artifacts/terraform-output-artifact.json"
            echo "::notice title=Artifact Found::ðŸ“„ Using JSON artifact file"
          elif [ -f "terraform-artifacts/terraform-output-artifact.txt" ]; then
            artifact_file="terraform-artifacts/terraform-output-artifact.txt"
            echo "::notice title=Artifact Found::ðŸ“„ Using text artifact file"
          else
            echo "::error title=No Artifact::âŒ No Terraform output artifact found"
            echo "::debug::Available files in terraform-artifacts/:"
            ls -la terraform-artifacts/ || echo "Directory not found"
            exit 1
          fi
          
          # Check file size and content
          file_size=$(stat -c%s "$artifact_file" 2>/dev/null || stat -f%z "$artifact_file" 2>/dev/null || echo "0")
          file_size_mb=$((file_size / 1024 / 1024))
          echo "::notice title=File Info::ðŸ“Š Artifact file size: $file_size bytes (${file_size_mb}MB)"
          
          # Validate file content without loading into memory
          if [ ! -s "$artifact_file" ]; then
            echo "::error title=Empty File::âŒ Terraform output artifact file is empty"
            exit 1
          fi
          
          # Check if file contains valid JSON (for .json files)
          if [[ "$artifact_file" == *.json ]]; then
            if ! jq empty "$artifact_file" 2>/dev/null; then
              echo "::error title=Invalid JSON::âŒ Terraform output artifact contains invalid JSON"
              exit 1
            fi
            
            # Handle empty JSON object case
            if [ "$(jq -r 'length' "$artifact_file")" = "0" ]; then
              echo "::notice title=Empty Output::ðŸ“„ Configuration has no outputs defined - creating placeholder files"
            else
              echo "::notice title=Valid Output::ðŸ“‹ Terraform output data validated (file-based processing)"
            fi
          else
            echo "::notice title=Text Output::ðŸ“‹ Processing text format artifact"
          fi
          
          # Create output directory structure
          mkdir -p "configurations/$config/outputs"
          
          # Generate timestamp for file naming
          timestamp=$(date +%Y%m%d-%H%M%S)
          
          # Set size threshold for large file handling (50MB)
          LARGE_FILE_THRESHOLD_MB=50
          
          # Determine processing approach based on file size
          if [ "$file_size_mb" -gt "$LARGE_FILE_THRESHOLD_MB" ]; then
            echo "::warning title=Large File::ðŸ“¦ File size (${file_size_mb}MB) exceeds threshold (${LARGE_FILE_THRESHOLD_MB}MB)"
            echo "::notice title=Processing Mode::ðŸ”§ Switching to large file processing mode"
            
            # For very large files, create summary + compressed archive
            output_filename="terraform-output-$timestamp-summary.$export_format"
            output_path="configurations/$config/outputs/$output_filename"
            archive_filename="terraform-output-$timestamp-full.json.gz"
            archive_path="configurations/$config/outputs/$archive_filename"
            
            # Create compressed archive of full data
            gzip -c "$artifact_file" > "$archive_path"
            echo "::notice title=Archive Created::ðŸ“¦ Full data archived as: $archive_filename"
            
            # Create summary output
            if [ "$export_format" = "json" ]; then
              create_summary_json "$artifact_file" "$output_path" "$include_metadata" "$config" "$file_size_mb"
            else
              create_summary_yaml "$artifact_file" "$output_path" "$include_metadata" "$config" "$file_size_mb"
            fi
            
            echo "output-is-summary=true" >> $GITHUB_OUTPUT
            echo "archive-filename=$archive_filename" >> $GITHUB_OUTPUT
            
          else
            echo "::notice title=Standard Processing::âœ… File size within normal limits"
            
            # Standard processing for normal-sized files
            output_filename="terraform-output-$timestamp.$export_format"
            output_path="configurations/$config/outputs/$output_filename"
            
            # Process output based on format using file-based operations
            if [ "$export_format" = "json" ]; then
              if [ "$include_metadata" = "true" ]; then
                # Create enhanced output with metadata using file-based processing
                temp_metadata=$(mktemp)
                cat > "$temp_metadata" << EOF
          {
            "metadata": {
              "generated_at": "$(date -u +"%Y-%m-%dT%H:%M:%SZ")",
              "configuration": "$config",
              "workflow_run": "${{ github.run_number }}",
              "generated_by": "${{ github.actor }}",
              "repository": "${{ github.repository }}",
              "ref": "${{ github.ref }}",
              "sha": "${{ github.sha }}",
              "export_format": "json",
              "file_size_mb": $file_size_mb
            }
          }
          EOF
                
                # Combine metadata and terraform output using file operations
                jq -s '.[0] + {"terraform_output": .[1]}' "$temp_metadata" "$artifact_file" > "$output_path"
                rm "$temp_metadata"
              else
                # Just copy and format the raw Terraform output
                jq '.' "$artifact_file" > "$output_path"
              fi
              
              echo "::notice title=JSON Created::ðŸ“„ JSON output created: $output_path"
              
            elif [ "$export_format" = "yaml" ]; then
              if [ "$include_metadata" = "true" ]; then
                # Create enhanced output with metadata using file-based processing
                temp_metadata=$(mktemp)
                cat > "$temp_metadata" << EOF
          {
            "metadata": {
              "generated_at": "$(date -u +"%Y-%m-%dT%H:%M:%SZ")",
              "configuration": "$config",
              "workflow_run": "${{ github.run_number }}",
              "generated_by": "${{ github.actor }}",
              "repository": "${{ github.repository }}",
              "ref": "${{ github.ref }}",
              "sha": "${{ github.sha }}",
              "export_format": "yaml",
              "file_size_mb": $file_size_mb
            }
          }
          EOF
                
                # Combine metadata and terraform output, then convert to YAML
                jq -s '.[0] + {"terraform_output": .[1]}' "$temp_metadata" "$artifact_file" | yq eval -P '.' > "$output_path"
                rm "$temp_metadata"
              else
                # Just convert the raw Terraform output to YAML
                jq '.' "$artifact_file" | yq eval -P '.' > "$output_path"
              fi
              
              echo "::notice title=YAML Created::ðŸ“„ YAML output created: $output_path"
            fi
            
            echo "output-is-summary=false" >> $GITHUB_OUTPUT
          fi
          
          # Helper function to create JSON summary
          create_summary_json() {
            local input_file="$1"
            local output_path="$2"
            local include_metadata="$3"
            local config="$4"
            local file_size_mb="$5"
            
            # Generate summary statistics without loading full content
            local total_keys
            total_keys=$(jq -r 'keys | length' "$input_file")
            local sample_keys
            sample_keys=$(jq -r 'keys | .[0:5]' "$input_file")
            
            if [ "$include_metadata" = "true" ]; then
              jq -n \
                --arg total_keys "$total_keys" \
                --argjson sample_keys "$sample_keys" \
                --arg file_size_mb "$file_size_mb" \
                --arg timestamp "$(date -u +"%Y-%m-%dT%H:%M:%SZ")" \
                --arg configuration "$config" \
                --arg workflow_run "${{ github.run_number }}" \
                --arg generated_by "${{ github.actor }}" \
                '{
                  "metadata": {
                    "generated_at": $timestamp,
                    "configuration": $configuration,
                    "workflow_run": $workflow_run,
                    "generated_by": $generated_by,
                    "export_format": "json",
                    "processing_mode": "summary",
                    "original_file_size_mb": ($file_size_mb | tonumber),
                    "note": "Large dataset summary. Full data available in compressed archive."
                  },
                  "terraform_output_summary": {
                    "total_outputs": ($total_keys | tonumber),
                    "sample_output_keys": $sample_keys,
                    "full_data_location": "See compressed archive in same directory",
                    "processing_note": "File too large for standard processing"
                  }
                }' > "$output_path"
            else
              jq -n \
                --arg total_keys "$total_keys" \
                --argjson sample_keys "$sample_keys" \
                '{
                  "total_outputs": ($total_keys | tonumber),
                  "sample_output_keys": $sample_keys,
                  "full_data_location": "See compressed archive in same directory"
                }' > "$output_path"
            fi
          }
          
          # Helper function to create YAML summary
          create_summary_yaml() {
            local input_file="$1"
            local output_path="$2"
            local include_metadata="$3"
            local config="$4"
            local file_size_mb="$5"
            
            # Create JSON summary first, then convert to YAML
            local temp_json
            temp_json=$(mktemp)
            create_summary_json "$input_file" "$temp_json" "$include_metadata" "$config" "$file_size_mb"
            yq eval -P '.' "$temp_json" > "$output_path"
            rm "$temp_json"
          }
          
          # Set common outputs
          echo "output-generated=true" >> $GITHUB_OUTPUT
          echo "output-filename=$output_filename" >> $GITHUB_OUTPUT
          
          # Generate processing metadata
          processing_metadata=$(jq -n \
            --arg timestamp "$(date -u +"%Y-%m-%dT%H:%M:%SZ")" \
            --arg configuration "$config" \
            --arg export_format "$export_format" \
            --arg output_filename "$output_filename" \
            --arg workflow_run "${{ github.run_number }}" \
            --arg generated_by "${{ github.actor }}" \
            --arg file_size_mb "$file_size_mb" \
            --argjson include_metadata "$include_metadata" \
            '{
              "processing": {
                "processed_at": $timestamp,
                "configuration": $configuration,
                "export_format": $export_format,
                "output_filename": $output_filename,
                "include_metadata": $include_metadata,
                "workflow_run": $workflow_run,
                "generated_by": $generated_by,
                "original_file_size_mb": ($file_size_mb | tonumber),
                "processing_mode": (if ($file_size_mb | tonumber) > 50 then "large_file_summary" else "standard" end)
              }
            }'
          )
          
          {
            echo "output-metadata<<METADATA_EOF"
            echo "$processing_metadata"
            echo "METADATA_EOF"
          } >> $GITHUB_OUTPUT
          
          echo "::notice title=Processing Complete::âœ… Output processing completed successfully"
      
      # Step 4: Commit output files to repository
      - name: Commit Generated Output Files
        run: |
          config="${{ github.event.inputs.configuration }}"
          output_filename="${{ steps.process-output.outputs.output-filename }}"
          export_format="${{ github.event.inputs.export_format }}"
          
          # Configure git for commit
          git config user.name "GitHub Actions"
          git config user.email "actions@github.com"
          
          # Add generated output files
          git add "configurations/$config/outputs/$output_filename"
          
          # Check if there are changes to commit
          if ! git diff --cached --quiet; then
            git commit -m "feat(output): generate $export_format output for $config configuration
          
          Configuration: $config
          Output File: $output_filename
          Export Format: $export_format
          Include Metadata: ${{ github.event.inputs.include_metadata }}
          Generated At: $(date -u +"%Y-%m-%dT%H:%M:%SZ")
          Workflow Run: ${{ github.run_number }}
          Executed By: @${{ github.actor }}
          
          This output was generated automatically by the Terraform Output workflow
          for migration and state analysis purposes."
            git push origin main
            
            echo "::notice title=Files Committed::ðŸ“ Output files committed to repository"
            echo "::notice title=Commit Details::ðŸ“‹ File: $output_filename, Format: $export_format"
          else
            echo "::notice title=No Changes::â„¹ï¸ No new output files to commit"
          fi
      
      # Step 5: Upload output as workflow artifact
      - name: Upload Terraform Output Artifact
        uses: actions/upload-artifact@v4
        with:
          name: terraform-output-${{ github.event.inputs.configuration }}-${{ github.run_number }}
          path: |
            configurations/${{ github.event.inputs.configuration }}/outputs/terraform-output-*.json
            configurations/${{ github.event.inputs.configuration }}/outputs/terraform-output-*.yaml
          retention-days: 30
          if-no-files-found: ignore  # Don't fail if only one format exists
          compression-level: 6
      
      # Step 6: Generate comprehensive execution summary
      - name: Generate Execution Summary
        run: |
          config="${{ github.event.inputs.configuration }}"
          export_format="${{ github.event.inputs.export_format }}"
          output_filename="${{ steps.process-output.outputs.output-filename }}"
          include_metadata="${{ github.event.inputs.include_metadata }}"
          is_summary="${{ steps.process-output.outputs.output-is-summary || 'false' }}"
          archive_filename="${{ steps.process-output.outputs.archive-filename || '' }}"
          
          echo "## ðŸ” Terraform Output Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### Output Generation Details" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "| Parameter | Value |" >> $GITHUB_STEP_SUMMARY
          echo "|-----------|-------|" >> $GITHUB_STEP_SUMMARY
          echo "| Configuration | \`$config\` |" >> $GITHUB_STEP_SUMMARY
          echo "| Export Format | \`$export_format\` |" >> $GITHUB_STEP_SUMMARY
          echo "| Output File | \`$output_filename\` |" >> $GITHUB_STEP_SUMMARY
          echo "| Include Metadata | \`$include_metadata\` |" >> $GITHUB_STEP_SUMMARY
          echo "| Processing Mode | $([ "$is_summary" = "true" ] && echo "**Large File Summary**" || echo "Standard") |" >> $GITHUB_STEP_SUMMARY
          echo "| Generated At | $(date +%Y-%m-%d\ %H:%M:%S) |" >> $GITHUB_STEP_SUMMARY
          echo "| Executed By | @${{ github.actor }} |" >> $GITHUB_STEP_SUMMARY
          echo "| Workflow Run | [${{ github.run_number }}](${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}) |" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          if [ "$is_summary" = "true" ]; then
            echo "### âš ï¸ Large Dataset Processing" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "Due to the large size of the Terraform output data, the system has created:" >> $GITHUB_STEP_SUMMARY
            echo "- **ðŸ“„ Summary File**: \`configurations/$config/outputs/$output_filename\` - Contains metadata and key statistics" >> $GITHUB_STEP_SUMMARY
            if [ -n "$archive_filename" ]; then
              echo "- **ðŸ“¦ Compressed Archive**: \`configurations/$config/outputs/$archive_filename\` - Complete dataset (gzipped)" >> $GITHUB_STEP_SUMMARY
            fi
            echo "- **ðŸ”§ Processing Mode**: Large file optimization enabled" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "### ðŸ“Š Why Summary Mode?" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "Large Terraform outputs (>50MB) can cause:" >> $GITHUB_STEP_SUMMARY
            echo "- Shell command length limitations" >> $GITHUB_STEP_SUMMARY
            echo "- Memory exhaustion during processing" >> $GITHUB_STEP_SUMMARY
            echo "- Git repository bloat" >> $GITHUB_STEP_SUMMARY
            echo "- Slow download/upload times" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "**Solution**: Summary + compressed archive provides the best of both worlds!" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "### ðŸ”“ Accessing Full Data" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "To access the complete dataset:" >> $GITHUB_STEP_SUMMARY
            echo "1. Download the compressed archive file" >> $GITHUB_STEP_SUMMARY
            echo "2. Extract using: \`gzip -d $archive_filename\`" >> $GITHUB_STEP_SUMMARY
            echo "3. Process the extracted JSON file with your preferred tools" >> $GITHUB_STEP_SUMMARY
          else
            echo "### âœ… Generation Successful" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "Terraform output has been successfully extracted and formatted:" >> $GITHUB_STEP_SUMMARY
            echo "- **Output Location**: \`configurations/$config/outputs/$output_filename\`" >> $GITHUB_STEP_SUMMARY
            echo "- **Format**: $export_format" >> $GITHUB_STEP_SUMMARY
            echo "- **Metadata Included**: $include_metadata" >> $GITHUB_STEP_SUMMARY
            echo "- **Processing Mode**: Standard (file size within normal limits)" >> $GITHUB_STEP_SUMMARY
          fi
          
          echo "- **Committed to Repository**: âœ… Available in main branch" >> $GITHUB_STEP_SUMMARY
          echo "- **Artifact Available**: âœ… Available for download for 30 days" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          echo "### ðŸ“Š Output Analysis" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "This output can be used for:" >> $GITHUB_STEP_SUMMARY
          echo "- **Migration Planning**: Understanding current Power Platform state" >> $GITHUB_STEP_SUMMARY
          echo "- **Compliance Auditing**: Documenting current governance policies" >> $GITHUB_STEP_SUMMARY
          echo "- **Configuration Backup**: Point-in-time snapshot of resources" >> $GITHUB_STEP_SUMMARY
          echo "- **Integration**: Feeding data into other tools and processes" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          echo "### ðŸ“‹ Next Steps" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          if [ "$is_summary" = "true" ]; then
            echo "1. **Review Summary**: Examine the generated summary file for key insights" >> $GITHUB_STEP_SUMMARY
            echo "2. **Extract Full Data**: Use the compressed archive for detailed analysis" >> $GITHUB_STEP_SUMMARY
            echo "3. **Process in Chunks**: Consider processing the full dataset in smaller chunks" >> $GITHUB_STEP_SUMMARY
            echo "4. **Optimize Queries**: Use the summary to optimize your data queries" >> $GITHUB_STEP_SUMMARY
          else
            echo "1. **Review Output**: Examine the generated $export_format file for insights" >> $GITHUB_STEP_SUMMARY
            echo "2. **Download Artifact**: Use the workflow artifact for offline analysis" >> $GITHUB_STEP_SUMMARY
            echo "3. **Migration Planning**: Use output data for planning Terraform migrations" >> $GITHUB_STEP_SUMMARY
            echo "4. **Documentation**: Update project documentation with current state" >> $GITHUB_STEP_SUMMARY
          fi
          echo "" >> $GITHUB_STEP_SUMMARY
          
          echo "### ðŸ”§ Migration Benefits" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "This workflow has been migrated to use the reusable-terraform-base workflow, providing:" >> $GITHUB_STEP_SUMMARY
          echo "- âœ… **93% code reduction** (580+ lines â†’ ~40 lines)" >> $GITHUB_STEP_SUMMARY
          echo "- âœ… **Standardized output processing with proven patterns**" >> $GITHUB_STEP_SUMMARY
          echo "- âœ… **Consistent error handling and format validation**" >> $GITHUB_STEP_SUMMARY
          echo "- âœ… **Enhanced metadata generation for better traceability**" >> $GITHUB_STEP_SUMMARY
          echo "- âœ… **Improved maintainability through proven composite actions**" >> $GITHUB_STEP_SUMMARY
          echo "- âœ… **Large file handling with automatic optimization**" >> $GITHUB_STEP_SUMMARY
