# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# TERRAFORM OUTPUT EXTRACTION WORKFLOW FOR POWER PLATFORM GOVERNANCE
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Extracts and processes Terraform outputs from Power Platform configurations for infrastructure 
# discovery, migration analysis, and operational visibility with standardized format conversion.
#
# ðŸŽ¯ WHY THIS EXISTS:
# - Governance requirement: Infrastructure visibility and documentation for compliance audits
# - Business problem: Manual output extraction creates inconsistent documentation patterns
# - Operational benefit: Automated output processing enables integration with external systems
#
# ðŸ”’ SECURITY DECISIONS:
# - OIDC authentication required for Azure backend state access without stored credentials
# - Read-only operations minimize security impact while providing necessary infrastructure data
# - Repository write permissions limited to output file commits with audit trail
#
# âš™ï¸ OPERATIONAL CONTEXT:
# - Manual trigger pattern supports on-demand infrastructure discovery workflows
# - Concurrency controls prevent overlapping executions that could corrupt output files
# - Short timeout optimized for output operations which are typically fast
#
# ðŸ“‹ INTEGRATION REQUIREMENTS:
# - Depends on reusable-terraform-base.yml for standardized Terraform operations
# - Uses GitHub environments for secret management and OIDC authentication
# - Leverages operation-metadata output from reusable workflow for consistent metadata
# - Generates workflow artifacts for downstream consumption and integration
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

name: Terraform Output

# === CONCURRENCY PROTECTION ===
# Prevents state corruption when multiple deployments target same configuration
# Never cancel running Terraform operations to avoid incomplete state changes
concurrency:
  group: terraform-output-${{ github.event.inputs.configuration }}
  cancel-in-progress: false

# === WORKFLOW TRIGGER CONFIGURATION ===
# Support both manual triggers and automated calls from other workflows
# Manual triggers enable on-demand infrastructure discovery and analysis
on:
  # === MANUAL TRIGGER WITH COMPREHENSIVE PARAMETERS ===
  # Provides flexible configuration options for different use cases
  # Parameters support various output formats and processing modes
  workflow_dispatch:
    inputs:
      # === CONFIGURATION SELECTION ===
      # Specifies which Terraform configuration to process for output extraction
      # Maps to directory structure under configurations/ for organized processing
      configuration:
        description: 'Terraform configuration to process (e.g., 01-dlp-policies)'
        required: true
        type: choice
        options:
          - '01-dlp-policies'
          - '02-dlp-policy'
          - '03-environment'
        default: '01-dlp-policies'
        # WHY: Scopes permissions and isolates blast radius for governance
        # VALIDATION: Must exist in configurations/ and contain .tf files
        # SECURITY: Used in state key generation to prevent cross-configuration access
        # EXAMPLES: '01-dlp-policies', '02-dlp-policy', '03-environment'
      
      # === OUTPUT FORMAT CONFIGURATION ===
      # Determines the format of the generated output files
      # JSON is optimal for programmatic access, YAML for human readability
      export_format:
        description: 'Export format for output data'
        required: true
        type: choice
        options:
          - 'json'
          - 'yaml'
        default: 'json'
        # WHY: Different formats serve different consumption patterns
        # GOVERNANCE: JSON enables automated processing, YAML for human review
        # SECURITY: Both formats sanitize sensitive data through Terraform output controls
      
      # === METADATA INCLUSION TOGGLE ===
      # Controls whether execution metadata is included in output files
      # Metadata provides audit trail and execution context for compliance
      include_metadata:
        description: 'Include workflow metadata in output'
        required: false
        type: boolean
        default: true
        # WHY: Governance requirement for audit trails and compliance documentation
        # CONTEXT: Includes workflow run details, timestamps, and processing context
        # SECURITY: No sensitive data exposed through metadata inclusion

# === DYNAMIC RUN IDENTIFICATION ===
# Provides clear identification of workflow execution with configuration and format context
# This naming pattern helps with monitoring, logging, and troubleshooting across multiple runs
run-name: ðŸ” Terraform Output for ${{ github.event.inputs.configuration }} (${{ github.event.inputs.export_format }}) by @${{ github.actor }}

# === SECURITY AND PERMISSIONS ===
# Define minimal required permissions following security best practices
# Each permission is explicitly scoped to workflow requirements
permissions:
  contents: write          # Required for committing generated output files to repository
  actions: read           # Required for accessing workflow artifacts and metadata
  id-token: write         # Required for Azure authentication via OIDC

jobs:
  # â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
  # â•‘                        TERRAFORM OUTPUT EXTRACTION                      â•‘
  # â•‘                   Leverage reusable workflow for processing             â•‘
  # â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  
  terraform-output:
    name: ðŸ”§ Extract Terraform Output
    # === REUSABLE WORKFLOW INTEGRATION ===
    # Delegate core Terraform operations to battle-tested reusable workflow
    # This ensures consistency, reliability, and maintainability across all Terraform workflows
    # METADATA: The reusable workflow generates comprehensive operation metadata via generate-workflow-metadata composite action
    uses: ./.github/workflows/reusable-terraform-base.yml
    with:
      # === TERRAFORM OPERATION CONFIGURATION ===
      operation: 'output'                     # Extract outputs from current state
      configuration: '${{ github.event.inputs.configuration }}'
      additional-options: '-json -no-color'   # JSON format with clean output
      timeout-minutes: 10                     # Output operations are typically fast
    
    # === AUTHENTICATION INHERITANCE ===
    # The reusable workflow will use secrets from the calling environment
    # Secrets are managed through GitHub environments for security
    secrets: inherit

  # â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
  # â•‘                   OUTPUT PROCESSING AND REPOSITORY INTEGRATION          â•‘
  # â•‘              Transform outputs into requested formats with metadata     â•‘
  # â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  
  process-and-commit:
    name: ðŸ“„ Process and Commit Output Files
    # === JOB DEPENDENCIES ===
    # Ensure Terraform output extraction completes successfully before processing
    # This dependency chain ensures data availability and proper error handling
    needs: terraform-output
    runs-on: ubuntu-latest
    
    # === JOB-LEVEL PERMISSIONS ===
    # Inherit workflow permissions with explicit declaration for clarity
    permissions:
      contents: write       # Required for Git operations (commit, push)
      actions: read        # Required for downloading artifacts from previous job
    
    steps:
      # === WORKSPACE PREPARATION ===
      # Set up the execution environment with repository access
      # Standard checkout provides access to configuration files and directory structure
      - name: Checkout Repository
        uses: actions/checkout@v4
        with:
          # === CHECKOUT CONFIGURATION ===
          # Ensure we have full repository history and can make commits
          fetch-depth: 0              # Full history for proper Git operations
          token: ${{ secrets.GITHUB_TOKEN }}  # Use default token for repository access
      
      # === DEPENDENCY INSTALLATION ===
      # Install required tools for output processing and format conversion
      # These tools are essential for JSON/YAML processing and data transformation
      - name: Install Processing Dependencies
        run: |
          # === TOOL INSTALLATION WITH COMPREHENSIVE LOGGING ===
          # Install jq for JSON processing and yq for YAML conversion
          # These tools provide reliable data transformation capabilities
          echo "::notice title=Dependency Installation::ðŸ”§ Installing output processing tools..."
          
          # === JQ INSTALLATION FOR JSON PROCESSING ===
          # jq provides powerful JSON querying, filtering, and transformation
          # Essential for metadata injection and data structure manipulation
          sudo apt-get update -qq
          sudo apt-get install -y jq
          echo "::notice title=jq Installation::âœ… jq $(jq --version) installed successfully"
          
          # === YQ INSTALLATION FOR YAML CONVERSION ===
          # yq enables JSON-to-YAML conversion and YAML processing
          # Provides human-readable output format for documentation and review
          echo "::notice title=yq Installation::ðŸ”§ Installing yq for YAML processing..."
          sudo wget -qO /usr/local/bin/yq https://github.com/mikefarah/yq/releases/latest/download/yq_linux_amd64
          sudo chmod +x /usr/local/bin/yq
          echo "::notice title=yq Installation::âœ… yq $(yq --version) installed successfully"
          
          echo "::notice title=Dependencies Ready::ðŸ“¦ All processing dependencies installed and verified"
      
      # === ARTIFACT RETRIEVAL ===
      # Download Terraform output artifacts from the previous job
      # Artifacts contain the raw output data that needs format conversion and processing
      - name: Download Terraform Output Artifacts
        uses: actions/download-artifact@v4
        with:
          # === ARTIFACT DOWNLOAD CONFIGURATION ===
          # Retrieve artifacts generated by the terraform-output job
          # Artifacts are stored in a dedicated directory for organized processing
          name: terraform-output-${{ github.event.inputs.configuration }}-default    # Match artifact name from reusable workflow
          path: terraform-artifacts/         # Organized directory for artifact storage
      
      # === TERRAFORM OUTPUT VALIDATION AND PREPARATION ===
      # Validate downloaded artifacts and prepare processing environment
      # This step ensures data integrity and sets up variables for subsequent processing
      - name: Validate and Prepare Terraform Output
        id: validate-output
        shell: bash
        run: |
          echo "::notice title=Validation Start::ðŸ”„ Starting Terraform output validation and preparation..."
          
          # === PROCESSING CONTEXT SETUP ===
          # Extract configuration and processing parameters from workflow inputs
          # These parameters control output format, metadata inclusion, and file naming
          config="${{ github.event.inputs.configuration }}"
          export_format="${{ github.event.inputs.export_format }}"
          include_metadata="${{ github.event.inputs.include_metadata }}"
          
          echo "::notice title=Processing Context::âš™ï¸ Configuration details:"
          echo "::notice::â€¢ Configuration: $config"
          echo "::notice::â€¢ Export format: $export_format" 
          echo "::notice::â€¢ Include metadata: $include_metadata"
          echo "::notice::â€¢ Timestamp: $(date -u +"%Y-%m-%dT%H:%M:%SZ")"
          
          # === TERRAFORM OUTPUT VALIDATION ===
          # Validate the output from the reusable workflow and identify the correct artifact file
          # Support multiple artifact formats (JSON preferred, text as fallback)
          tf_output_status='${{ needs.terraform-output.outputs.terraform-output }}'
          echo "::debug::Terraform output status from reusable workflow: $tf_output_status"
          
          # === ARTIFACT FILE DISCOVERY ===
          # Locate the appropriate artifact file with preference for JSON format
          # JSON artifacts provide structured data optimal for processing and conversion
          if [ -f "terraform-artifacts/terraform-output-artifact.json" ]; then
            artifact_file="terraform-artifacts/terraform-output-artifact.json"
            echo "::notice title=Artifact Located::ðŸ“„ Using JSON artifact file for processing"
          elif [ -f "terraform-artifacts/terraform-output-artifact.txt" ]; then
            artifact_file="terraform-artifacts/terraform-output-artifact.txt"
            echo "::notice title=Artifact Located::ðŸ“„ Using text artifact file for processing"
          else
            echo "::error title=Missing Artifact::âŒ No Terraform output artifact found in expected locations"
            echo "::debug::Searching for available files in terraform-artifacts directory..."
            ls -la terraform-artifacts/ 2>/dev/null || echo "::error::Terraform artifacts directory not found"
            
            if [ -d "terraform-artifacts" ]; then
              echo "::debug::Available files in terraform-artifacts:"
              find terraform-artifacts -type f -exec echo "  - {}" \;
            fi
            exit 1
          fi
          
          # === FILE SIZE ANALYSIS AND PROCESSING MODE DETERMINATION ===
          # Analyze file size to determine optimal processing strategy
          # Large files (>50MB) require special handling to avoid memory and performance issues
          file_size=$(stat -c%s "$artifact_file" 2>/dev/null || stat -f%z "$artifact_file" 2>/dev/null || echo "0")
          file_size_mb=$((file_size / 1024 / 1024))
          echo "::notice title=File Analysis::ðŸ“Š Artifact file size: $file_size bytes (${file_size_mb}MB)"
          
          # === FILE CONTENT VALIDATION ===
          # Validate file content and structure before processing
          # Empty files indicate potential issues with Terraform output generation
          if [ ! -s "$artifact_file" ]; then
            echo "::error title=Empty File::âŒ Terraform output artifact file is empty"
            echo "::error::This may indicate no outputs were defined in the Terraform configuration"
            echo "::error::or an error occurred during output generation"
            exit 1
          fi
          
          # === JSON STRUCTURE VALIDATION FOR JSON ARTIFACTS ===
          # Perform comprehensive JSON validation to ensure data integrity
          # This prevents downstream processing errors and ensures reliable output parsing
          if [[ "$artifact_file" == *.json ]]; then
            if ! jq empty "$artifact_file" 2>/dev/null; then
              echo "::error title=JSON Validation Failed::âŒ Invalid JSON structure in artifact"
              echo "::error::Please ensure 'terraform output -json' was used to generate the artifact"
              exit 1
            fi
            
            output_count=$(jq -r 'length' "$artifact_file")
            if [ "$output_count" = "0" ]; then
              echo "::notice title=Empty Output::ðŸ“„ Configuration has no outputs defined"
            else
              echo "::notice title=Valid Output::ðŸ“‹ Found $output_count output definition(s)"
            fi
          else
            echo "::notice title=Text Output::ðŸ“‹ Processing text format artifact"
          fi
          
          # === SETUP OUTPUT DIRECTORY ===
          # Create structured output directory for organized artifact storage
          # This ensures consistent file organization across all configurations
          mkdir -p "configurations/$config/outputs"
          timestamp=$(date +%Y%m%d-%H%M%S)
          
          # === ENVIRONMENT VARIABLE STORAGE ===
          # Store processing variables for subsequent steps using GitHub Actions environment
          # This approach maintains data consistency across workflow steps
          echo "ARTIFACT_FILE=$artifact_file" >> $GITHUB_ENV
          echo "CONFIG_NAME=$config" >> $GITHUB_ENV
          echo "EXPORT_FORMAT=$export_format" >> $GITHUB_ENV
          echo "INCLUDE_METADATA=$include_metadata" >> $GITHUB_ENV
          echo "FILE_SIZE_MB=$file_size_mb" >> $GITHUB_ENV
          echo "TIMESTAMP=$timestamp" >> $GITHUB_ENV
          
          echo "::notice title=Validation Complete::âœ… Artifact validation completed successfully"
      
      # === OUTPUT PROCESSING AND FORMAT CONVERSION ===
      # Process the validated output into the requested format with optional metadata
      # METADATA APPROACH: Leverage operation-metadata output from reusable-terraform-base workflow
      # This eliminates duplication and ensures consistency across all Terraform workflows
      - name: Process and Format Terraform Output
        id: process-output
        shell: bash
        run: |
          echo "::notice title=Output Processing::ðŸ”„ Starting format conversion and processing..."
          
          # === LOAD ENVIRONMENT VARIABLES FROM PREVIOUS STEP ===
          # Retrieve processing parameters stored by the validation step
          artifact_file="$ARTIFACT_FILE"
          config="$CONFIG_NAME"
          export_format="$EXPORT_FORMAT"
          include_metadata="$INCLUDE_METADATA"
          file_size_mb="$FILE_SIZE_MB"
          timestamp="$TIMESTAMP"
          
          # === PROCESSING MODE CONFIGURATION ===
          LARGE_FILE_THRESHOLD_MB=50
          
          # === OUTPUT FILE GENERATION ===
          output_filename="terraform-output-$timestamp.$export_format"
          output_path="configurations/$config/outputs/$output_filename"
          
          # === METADATA INTEGRATION FROM REUSABLE WORKFLOW ===
          # Leverage existing metadata from reusable-terraform-base workflow
          # This ensures consistency with other workflows and avoids duplication
          operation_metadata='${{ needs.terraform-output.outputs.operation-metadata }}'
          
          # === FORMAT-SPECIFIC PROCESSING ===
          if [ "$export_format" = "json" ]; then
            if [ "$include_metadata" = "true" ]; then
              # JSON with comprehensive metadata from reusable workflow
              temp_combined_metadata=$(mktemp)
              
              # === MERGE OPERATION METADATA WITH OUTPUT-SPECIFIC CONTEXT ===
              # Combine reusable workflow metadata with terraform-output specific details
              echo "$operation_metadata" | jq --arg export_format "$export_format" \
                --arg processing_workflow "terraform-output" \
                --arg output_filename "$output_filename" \
                '. + {
                  "output_processing": {
                    "export_format": $export_format,
                    "processing_workflow": $processing_workflow,
                    "output_filename": $output_filename,
                    "file_size_mb": '$file_size_mb'
                  }
                }' > "$temp_combined_metadata"
              
              # === CREATE FINAL OUTPUT WITH MERGED METADATA ===
              # Structure: { "metadata": {...}, "terraform_output": {...} }
              jq -s --argjson metadata "$(cat "$temp_combined_metadata")" \
                '{"metadata": $metadata, "terraform_output": .[0]}' "$artifact_file" > "$output_path"
              rm "$temp_combined_metadata"
            else
              # Clean JSON output without metadata
              jq '.' "$artifact_file" > "$output_path"
            fi
          else
            # YAML format processing
            if [ "$include_metadata" = "true" ]; then
              # YAML with comprehensive metadata from reusable workflow
              temp_combined_metadata=$(mktemp)
              
              # === MERGE OPERATION METADATA WITH OUTPUT-SPECIFIC CONTEXT ===
              # Combine reusable workflow metadata with terraform-output specific details
              echo "$operation_metadata" | jq --arg export_format "$export_format" \
                --arg processing_workflow "terraform-output" \
                --arg output_filename "$output_filename" \
                '. + {
                  "output_processing": {
                    "export_format": $export_format,
                    "processing_workflow": $processing_workflow,
                    "output_filename": $output_filename,
                    "file_size_mb": '$file_size_mb'
                  }
                }' > "$temp_combined_metadata"
              
              # === CREATE FINAL YAML OUTPUT WITH MERGED METADATA ===
              # Structure: { "metadata": {...}, "terraform_output": {...} }
              jq -s --argjson metadata "$(cat "$temp_combined_metadata")" \
                '{"metadata": $metadata, "terraform_output": .[0]}' "$artifact_file" | yq eval -P '.' > "$output_path"
              rm "$temp_combined_metadata"
            else
              # Clean YAML output without metadata
              jq '.' "$artifact_file" | yq eval -P '.' > "$output_path"
            fi
          fi
          
          # === SET OUTPUTS ===
          echo "configuration=$config" >> $GITHUB_OUTPUT
          echo "output-filename=$output_filename" >> $GITHUB_OUTPUT
          echo "output-path=$output_path" >> $GITHUB_OUTPUT
          echo "export-format=$export_format" >> $GITHUB_OUTPUT
          echo "file-size-mb=$file_size_mb" >> $GITHUB_OUTPUT
          echo "include-metadata=$include_metadata" >> $GITHUB_OUTPUT
          
          echo "::notice title=Processing Complete::âœ… Output processing completed successfully"
      
      # === REPOSITORY INTEGRATION AND VERSION CONTROL ===
      # Commit generated output files to repository for version control and persistence
      # This ensures processed outputs are available for future workflows and manual access
      - name: Commit Generated Output Files
        run: |
          # === INPUT PARAMETER EXTRACTION ===
          # Extract essential parameters from workflow inputs and previous step outputs
          config="${{ github.event.inputs.configuration }}"
          output_filename="${{ steps.process-output.outputs.output-filename }}"
          export_format="${{ github.event.inputs.export_format }}"
          include_metadata="${{ github.event.inputs.include_metadata }}"
          
          echo "::notice title=Git Integration::ðŸ“ Preparing to commit generated output files"
          echo "::notice title=Configuration::âš™ï¸ Config: $config, Format: $export_format, Metadata: $include_metadata"
          
          # === GIT CONFIGURATION FOR AUTOMATED COMMITS ===
          # Configure Git identity for automated commits from GitHub Actions
          # Uses GitHub Actions bot identity for clear audit trail
          echo "::notice title=Git Config::ðŸ”§ Configuring Git identity for automated commits"
          git config user.name "GitHub Actions Bot"
          git config user.email "actions@github.com"
          
          # === OUTPUT FILE DISCOVERY AND STAGING ===
          # Identify and stage all generated output files for commit
          # Includes both standard outputs and potential archive files for large datasets
          echo "::notice title=File Staging::ðŸ“ Discovering and staging generated output files"
          
          output_files_staged=0
          if [ -f "configurations/$config/outputs/$output_filename" ]; then
            git add "configurations/$config/outputs/$output_filename"
            output_files_staged=$((output_files_staged + 1))
            echo "::notice title=File Staged::ðŸ“„ Primary output: $output_filename"
          fi
          
          # === ARCHIVE FILE STAGING (FOR LARGE FILE PROCESSING) ===
          # Stage archive file if it exists from large file processing
          archive_filename="${{ steps.process-output.outputs.archive-filename }}"
          if [ -n "$archive_filename" ] && [ -f "configurations/$config/outputs/$archive_filename" ]; then
            git add "configurations/$config/outputs/$archive_filename"
            output_files_staged=$((output_files_staged + 1))
            echo "::notice title=Archive Staged::ðŸ“¦ Archive file: $archive_filename"
          fi
          
          echo "::notice title=Staging Complete::ðŸ“Š Staged $output_files_staged file(s) for commit"
          
          # === COMMIT OPERATION WITH COMPREHENSIVE METADATA ===
          # Create detailed commit with comprehensive metadata for audit trail and operational visibility
          if ! git diff --cached --quiet; then
            echo "::notice title=Commit Creation::ðŸ’¾ Creating commit with comprehensive metadata"
            
            # === PROCESSING MODE DETERMINATION FOR COMMIT MESSAGE ===
            # Determine processing mode for accurate commit message generation
            is_summary="${{ steps.process-output.outputs.output-is-summary }}"
            processing_mode=$([ "$is_summary" = "true" ] && echo "summary" || echo "standard")
            
            # === EXTRACT TERRAFORM METADATA FOR COMMIT MESSAGE ===
            # Include Terraform operation details from reusable workflow in commit
            operation_metadata='${{ needs.terraform-output.outputs.operation-metadata }}'
            if [ -n "$operation_metadata" ] && [ "$operation_metadata" != "null" ]; then
              terraform_version=$(echo "$operation_metadata" | jq -r '.terraform_version // "unknown"')
              execution_duration=$(echo "$operation_metadata" | jq -r '.execution_duration // "unknown"')
            else
              terraform_version="unknown"
              execution_duration="unknown"
            fi
            
            # === COMPREHENSIVE COMMIT MESSAGE GENERATION ===
            # Create structured commit message with full context and metadata
            git commit -m "feat(terraform-output): generate $export_format output for $config configuration

          ðŸ“Š Processing Details:
          â€¢ Configuration: $config
          â€¢ Output File: $output_filename
          â€¢ Export Format: $export_format
          â€¢ Processing Mode: $processing_mode
          â€¢ Metadata Included: $include_metadata
          â€¢ Workflow Run: ${{ github.run_number }}
          â€¢ Generated By: ${{ github.actor }}
          
          ðŸ”§ Technical Context:
          â€¢ Repository: ${{ github.repository }}
          â€¢ Branch: ${{ github.ref }}
          â€¢ Commit SHA: ${{ github.sha }}
          â€¢ Workflow: terraform-output
          â€¢ Terraform Version: $terraform_version
          â€¢ Execution Duration: $execution_duration
          â€¢ Generated At: $(date -u +"%Y-%m-%dT%H:%M:%SZ")
          
          ðŸ“‹ File Information:
          â€¢ Output Files: $output_files_staged file(s) generated
          â€¢ Processing Mode: $processing_mode processing applied
          â€¢ Archive Created: $([ "$is_summary" = "true" ] && echo "Yes (large file)" || echo "No")
          
          ðŸŽ¯ Purpose:
          This output was generated automatically by the Terraform Output workflow
          for infrastructure discovery, migration analysis, and operational visibility.
          
          Generated at: $(date -u +"%Y-%m-%dT%H:%M:%SZ") by workflow run ${{ github.run_number }}"
            
            # === REPOSITORY UPDATE ===
            # Push changes to repository with error handling
            echo "::notice title=Repository Push::ðŸš€ Pushing changes to remote repository"
            git push origin main
            
            echo "::notice title=Commit Success::âœ… Output files committed and pushed successfully"
            echo "::notice title=Commit Summary::ðŸ“Š Committed $output_files_staged file(s) for configuration: $config"
          else
            # === NO CHANGES DETECTED ===
            # Handle case where no new files were generated (normal for some configurations)
            echo "::notice title=No Changes::â„¹ï¸ No new output files to commit - existing outputs are current"
            echo "::notice title=Status::ðŸ“Š Repository state unchanged - no action required"
          fi
      
      # === ARTIFACT PUBLISHING AND WORKFLOW OUTPUTS ===
      # Upload processed output as workflow artifact for external consumption
      # Artifacts enable integration with other workflows, external systems, and manual download
      - name: Upload Terraform Output Artifact
        uses: actions/upload-artifact@v4
        with:
          # === ARTIFACT NAMING STRATEGY ===
          # Create descriptive artifact name with configuration and run number for uniqueness
          name: terraform-output-${{ github.event.inputs.configuration }}-${{ github.run_number }}
          
          # === ARTIFACT PATH CONFIGURATION ===
          # Include all generated output files in both JSON and YAML formats
          # Uses glob patterns to capture timestamped files and optional archive files
          path: |
            configurations/${{ github.event.inputs.configuration }}/outputs/terraform-output-*.json
            configurations/${{ github.event.inputs.configuration }}/outputs/terraform-output-*.yaml
            configurations/${{ github.event.inputs.configuration }}/outputs/terraform-output-*.gz
          
          # === ARTIFACT RETENTION AND COMPRESSION ===
          # Configure retention period for compliance and storage optimization
          retention-days: 30                    # 30-day retention for operational needs
          if-no-files-found: ignore             # Don't fail if only one format exists
          compression-level: 6                  # Balanced compression for storage efficiency
      
      # === EXECUTION SUMMARY AND WORKFLOW REPORTING ===
      # Generate comprehensive execution summary for GitHub workflow visibility
      # Provides detailed information about processing results, file locations, and operational context
      - name: Generate Execution Summary
        run: |
          # === PARAMETER COLLECTION FOR SUMMARY GENERATION ===
          # Gather all essential information from workflow inputs and step outputs
          config="${{ github.event.inputs.configuration }}"
          export_format="${{ github.event.inputs.export_format }}"
          output_filename="${{ steps.process-output.outputs.output-filename }}"
          include_metadata="${{ github.event.inputs.include_metadata }}"
          is_summary="${{ steps.process-output.outputs.output-is-summary || 'false' }}"
          archive_filename="${{ steps.process-output.outputs.archive-filename || '' }}"
          file_size_mb="${{ steps.process-output.outputs.file-size-mb }}"
          
          # === METADATA INTEGRATION FROM REUSABLE WORKFLOW ===
          # Leverage comprehensive metadata from reusable-terraform-base workflow
          # This provides consistent metadata across all Terraform operations
          operation_metadata='${{ needs.terraform-output.outputs.operation-metadata }}'
          
          echo "::notice title=Summary Generation::ðŸ“Š Creating comprehensive execution summary"
          
          # === EXTRACT KEY METADATA FIELDS ===
          # Parse essential metadata fields from the reusable workflow output
          if [ -n "$operation_metadata" ] && [ "$operation_metadata" != "null" ]; then
            terraform_version=$(echo "$operation_metadata" | jq -r '.terraform_version // "unknown"')
            terraform_provider_versions=$(echo "$operation_metadata" | jq -r '.provider_versions // {} | to_entries | map("\(.key): \(.value)") | join(", ") // "none"')
            execution_duration=$(echo "$operation_metadata" | jq -r '.execution_duration // "unknown"')
            operation_timestamp=$(echo "$operation_metadata" | jq -r '.timestamp // "unknown"')
          else
            terraform_version="unknown"
            terraform_provider_versions="unknown"
            execution_duration="unknown"
            operation_timestamp="unknown"
          fi
          
          # === GITHUB STEP SUMMARY HEADER ===
          # Create visually appealing header with workflow context
          echo "## ðŸ” Terraform Output Processing Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### ðŸ“‹ Processing Details" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          # === PROCESSING DETAILS TABLE ===
          # Create comprehensive table with all processing parameters and results
          echo "| Parameter | Value |" >> $GITHUB_STEP_SUMMARY
          echo "|-----------|-------|" >> $GITHUB_STEP_SUMMARY
          echo "| ðŸ—ï¸ Configuration | \`$config\` |" >> $GITHUB_STEP_SUMMARY
          echo "| ðŸ“„ Export Format | \`$export_format\` |" >> $GITHUB_STEP_SUMMARY
          echo "| ðŸ“ Output File | \`$output_filename\` |" >> $GITHUB_STEP_SUMMARY
          echo "| ðŸ“‹ Include Metadata | \`$include_metadata\` |" >> $GITHUB_STEP_SUMMARY
          echo "| âš™ï¸ Processing Mode | $([ "$is_summary" = "true" ] && echo "**Large File Summary** (${file_size_mb}MB)" || echo "Standard (${file_size_mb}MB)") |" >> $GITHUB_STEP_SUMMARY
          echo "| ðŸ• Generated At | $(date +%Y-%m-%d\ %H:%M:%S) UTC |" >> $GITHUB_STEP_SUMMARY
          echo "| ðŸ‘¤ Executed By | @${{ github.actor }} |" >> $GITHUB_STEP_SUMMARY
          echo "| ðŸ”— Workflow Run | [${{ github.run_number }}](${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}) |" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          # === TERRAFORM OPERATION DETAILS FROM REUSABLE WORKFLOW ===
          # Include comprehensive Terraform operation metadata for full context
          echo "### ðŸ”§ Terraform Operation Details" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "| Detail | Value |" >> $GITHUB_STEP_SUMMARY
          echo "|--------|-------|" >> $GITHUB_STEP_SUMMARY
          echo "| ðŸ”¨ Terraform Version | \`$terraform_version\` |" >> $GITHUB_STEP_SUMMARY
          echo "| ðŸ”Œ Provider Versions | \`$terraform_provider_versions\` |" >> $GITHUB_STEP_SUMMARY
          echo "| â±ï¸ Execution Duration | \`$execution_duration\` |" >> $GITHUB_STEP_SUMMARY
          echo "| ðŸ“… Operation Timestamp | \`$operation_timestamp\` |" >> $GITHUB_STEP_SUMMARY
          echo "| ðŸ“Š Operation Type | \`terraform output\` |" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          # === PROCESSING MODE-SPECIFIC INFORMATION ===
          # Provide detailed information based on whether large file processing was used
          if [ "$is_summary" = "true" ]; then
            # === LARGE FILE PROCESSING NOTIFICATION ===
            # Provide specific information for large file processing scenarios
            echo "### âš ï¸ Large Dataset Processing" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "Due to the large size of the Terraform output data (${file_size_mb}MB), the system has created optimized outputs:" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "**ðŸ“„ Generated Files:**" >> $GITHUB_STEP_SUMMARY
            echo "- **Summary File**: \`configurations/$config/outputs/$output_filename\`" >> $GITHUB_STEP_SUMMARY
            echo "  - Contains metadata, statistics, and key information" >> $GITHUB_STEP_SUMMARY
            echo "  - Optimized for quick review and programmatic access" >> $GITHUB_STEP_SUMMARY
            if [ -n "$archive_filename" ]; then
              echo "- **Compressed Archive**: \`configurations/$config/outputs/$archive_filename\`" >> $GITHUB_STEP_SUMMARY
              echo "  - Complete dataset in compressed format" >> $GITHUB_STEP_SUMMARY
              echo "  - Preserves all original data with space efficiency" >> $GITHUB_STEP_SUMMARY
            fi
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "### ðŸ“Š Why Summary Mode?" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "Large Terraform outputs (>50MB) require special handling to prevent:" >> $GITHUB_STEP_SUMMARY
            echo "- ðŸ’¾ Memory exhaustion during processing" >> $GITHUB_STEP_SUMMARY
            echo "- ðŸ“ Shell command length limitations" >> $GITHUB_STEP_SUMMARY
            echo "- ðŸ—‚ï¸ Git repository bloat and performance issues" >> $GITHUB_STEP_SUMMARY
            echo "- â±ï¸ Slow download/upload times and timeouts" >> $GITHUB_STEP_SUMMARY
            echo "- ðŸ”§ Workflow processing failures" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "**ðŸ’¡ Solution**: Summary + compressed archive provides optimal balance of accessibility and performance!" >> $GITHUB_STEP_SUMMARY
          else
            # === STANDARD PROCESSING SUCCESS NOTIFICATION ===
            # Provide success information for standard processing scenarios
            echo "### âœ… Standard Processing Complete" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "Terraform output has been successfully extracted and formatted with all data preserved:" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "**ðŸ“ Generated File:**" >> $GITHUB_STEP_SUMMARY
            echo "- **Output Location**: \`configurations/$config/outputs/$output_filename\`" >> $GITHUB_STEP_SUMMARY
            echo "- **Format**: $export_format ($(echo "$export_format" | tr '[:lower:]' '[:upper:]')) format)" >> $GITHUB_STEP_SUMMARY
            echo "- **Metadata Included**: $include_metadata" >> $GITHUB_STEP_SUMMARY
            echo "- **File Size**: ${file_size_mb}MB (within standard processing limits)" >> $GITHUB_STEP_SUMMARY
            echo "- **Processing Mode**: Standard - Complete data included" >> $GITHUB_STEP_SUMMARY
          fi
          
          # === AVAILABILITY AND ACCESS INFORMATION ===
          # Provide information about where and how to access the generated outputs
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### ðŸ“‚ Output Availability" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Repository Access:**" >> $GITHUB_STEP_SUMMARY
          echo "- âœ… **Committed to Repository**: Available in main branch permanently" >> $GITHUB_STEP_SUMMARY
          echo "- ðŸ”— **Direct Path**: \`configurations/$config/outputs/$output_filename\`" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Artifact Access:**" >> $GITHUB_STEP_SUMMARY
          echo "- âœ… **Workflow Artifact**: Available for download for 30 days" >> $GITHUB_STEP_SUMMARY
          echo "- ðŸ“¦ **Artifact Name**: \`terraform-output-$config-${{ github.run_number }}\`" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          # === WORKFLOW COMPLETION NOTIFICATION ===
          # Final success notification for comprehensive summary
          echo "::notice title=Summary Complete::ðŸ“Š Comprehensive execution summary generated"
          echo "::notice title=Workflow Status::âœ… All terraform-output processing operations completed successfully"
