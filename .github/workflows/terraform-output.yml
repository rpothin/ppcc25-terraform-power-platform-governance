# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# TERRAFORM OUTPUT EXTRACTION WORKFLOW FOR POWER PLATFORM GOVERNANCE
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# Extracts and processes Terraform outputs from Power Platform configurations for infrastructure 
# discovery, migration analysis, and operational visibility with standardized format conversion.
#
# üéØ WHY THIS EXISTS:
# - Governance requirement: Infrastructure visibility and documentation for compliance audits
# - Business problem: Manual output extraction creates inconsistent documentation patterns
# - Operational benefit: Automated output processing enables integration with external systems
#
# üîí SECURITY DECISIONS:
# - OIDC authentication required for Azure backend state access without stored credentials
# - Read-only operations minimize security impact while providing necessary infrastructure data
# - Repository write permissions limited to output file commits with audit trail
#
# ‚öôÔ∏è OPERATIONAL CONTEXT:
# - Manual trigger pattern supports on-demand infrastructure discovery workflows
# - Concurrency controls prevent overlapping executions that could corrupt output files
# - Short timeout optimized for output operations which are typically fast
#
# üìã INTEGRATION REQUIREMENTS:
# - Depends on reusable-terraform-base.yml for standardized Terraform operations
# - Uses GitHub environments for secret management and OIDC authentication
# - Leverages operation-metadata output from reusable workflow for consistent metadata
# - Generates workflow artifacts for downstream consumption and integration
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

name: Terraform Output

# === CONCURRENCY PROTECTION ===
# Prevents state corruption when multiple deployments target same configuration
# Never cancel running Terraform operations to avoid incomplete state changes
concurrency:
  group: terraform-output-${{ github.event.inputs.configuration }}
  cancel-in-progress: false

# === WORKFLOW TRIGGER CONFIGURATION ===
# Support both manual triggers and automated calls from other workflows
# Manual triggers enable on-demand infrastructure discovery and analysis
on:
  # === MANUAL TRIGGER WITH COMPREHENSIVE PARAMETERS ===
  # Provides flexible configuration options for different use cases
  # Parameters support various output formats and processing modes
  workflow_dispatch:
    inputs:
      # === CONFIGURATION SELECTION ===
      # Specifies which Terraform configuration to process for output extraction
      # Maps to directory structure under configurations/ for organized processing
      configuration:
        description: 'Terraform configuration to process (e.g., 01-dlp-policies)'
        required: true
        type: choice
        options:
          - '01-dlp-policies'
          - '02-dlp-policy'
          - '03-environment'
        default: '01-dlp-policies'
        # WHY: Scopes permissions and isolates blast radius for governance
        # VALIDATION: Must exist in configurations/ and contain .tf files
        # SECURITY: Used in state key generation to prevent cross-configuration access
        # EXAMPLES: '01-dlp-policies', '02-dlp-policy', '03-environment'
      
      # === OUTPUT FORMAT CONFIGURATION ===
      # Determines the format of the generated output files
      # JSON is optimal for programmatic access, YAML for human readability
      export_format:
        description: 'Export format for output data'
        required: true
        type: choice
        options:
          - 'json'
          - 'yaml'
        default: 'json'
        # WHY: Different formats serve different consumption patterns
        # GOVERNANCE: JSON enables automated processing, YAML for human review
        # SECURITY: Both formats sanitize sensitive data through Terraform output controls
      
      # === METADATA INCLUSION TOGGLE ===
      # Controls whether execution metadata is included in output files
      # Metadata provides audit trail and execution context for compliance
      include_metadata:
        description: 'Include workflow metadata in output'
        required: false
        type: boolean
        default: true
        # WHY: Governance requirement for audit trails and compliance documentation
        # CONTEXT: Includes workflow run details, timestamps, and processing context
        # SECURITY: No sensitive data exposed through metadata inclusion

# === DYNAMIC RUN IDENTIFICATION ===
# Provides clear identification of workflow execution with configuration and format context
# This naming pattern helps with monitoring, logging, and troubleshooting across multiple runs
run-name: üîç Terraform Output for ${{ github.event.inputs.configuration }} (${{ github.event.inputs.export_format }}) by @${{ github.actor }}

# === SECURITY AND PERMISSIONS ===
# Define minimal required permissions following security best practices
# Each permission is explicitly scoped to workflow requirements
permissions:
  contents: write          # Required for committing generated output files to repository
  actions: read           # Required for accessing workflow artifacts and metadata
  id-token: write         # Required for Azure authentication via OIDC

jobs:
  # ‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó
  # ‚ïë                        TERRAFORM OUTPUT EXTRACTION                      ‚ïë
  # ‚ïë                   Leverage reusable workflow for processing             ‚ïë
  # ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù
  
  terraform-output:
    name: üîß Extract Terraform Output
    # === REUSABLE WORKFLOW INTEGRATION ===
    # Delegate core Terraform operations to battle-tested reusable workflow
    # This ensures consistency, reliability, and maintainability across all Terraform workflows
    # METADATA: The reusable workflow generates comprehensive operation metadata via generate-workflow-metadata composite action
    uses: ./.github/workflows/reusable-terraform-base.yml
    with:
      # === TERRAFORM OPERATION CONFIGURATION ===
      operation: 'output'                     # Extract outputs from current state
      configuration: '${{ github.event.inputs.configuration }}'
      additional-options: '-json -no-color'   # JSON format with clean output
      timeout-minutes: 10                     # Output operations are typically fast
    
    # === AUTHENTICATION INHERITANCE ===
    # The reusable workflow will use secrets from the calling environment
    # Secrets are managed through GitHub environments for security
    secrets: inherit

  # ‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó
  # ‚ïë                   OUTPUT PROCESSING AND REPOSITORY INTEGRATION          ‚ïë
  # ‚ïë              Transform outputs into requested formats with metadata     ‚ïë
  # ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù
  
  process-and-commit:
    name: üìÑ Process and Commit Output Files
    # === JOB DEPENDENCIES ===
    # Ensure Terraform output extraction completes successfully before processing
    # This dependency chain ensures data availability and proper error handling
    needs: terraform-output
    runs-on: ubuntu-latest
    
    # === JOB-LEVEL PERMISSIONS ===
    # Inherit workflow permissions with explicit declaration for clarity
    permissions:
      contents: write       # Required for Git operations (commit, push)
      actions: read        # Required for downloading artifacts from previous job
    
    steps:
      # === WORKSPACE PREPARATION ===
      # Set up the execution environment with repository access
      # Standard checkout provides access to configuration files and directory structure
      - name: Checkout Repository
        uses: actions/checkout@v4
        with:
          # === CHECKOUT CONFIGURATION ===
          # Ensure we have full repository history and can make commits
          fetch-depth: 0              # Full history for proper Git operations
          token: ${{ secrets.GITHUB_TOKEN }}  # Use default token for repository access
      
      # === DEPENDENCY INSTALLATION ===
      # Install required tools for output processing and format conversion
      # These tools are essential for JSON/YAML processing and data transformation
      - name: Install Processing Dependencies
        run: |
          # === TOOL INSTALLATION WITH COMPREHENSIVE LOGGING ===
          # Install jq for JSON processing and yq for YAML conversion
          # These tools provide reliable data transformation capabilities
          echo "::notice title=Dependency Installation::üîß Installing output processing tools..."
          
          # === JQ INSTALLATION FOR JSON PROCESSING ===
          # jq provides powerful JSON querying, filtering, and transformation
          # Essential for metadata injection and data structure manipulation
          sudo apt-get update -qq
          sudo apt-get install -y jq
          echo "::notice title=jq Installation::‚úÖ jq $(jq --version) installed successfully"
          
          # === YQ INSTALLATION FOR YAML CONVERSION ===
          # yq enables JSON-to-YAML conversion and YAML processing
          # Provides human-readable output format for documentation and review
          echo "::notice title=yq Installation::üîß Installing yq for YAML processing..."
          sudo wget -qO /usr/local/bin/yq https://github.com/mikefarah/yq/releases/latest/download/yq_linux_amd64
          sudo chmod +x /usr/local/bin/yq
          echo "::notice title=yq Installation::‚úÖ yq $(yq --version) installed successfully"
          
          echo "::notice title=Dependencies Ready::üì¶ All processing dependencies installed and verified"
      
      # === ARTIFACT RETRIEVAL ===
      # Download Terraform output artifacts from the previous job
      # Artifacts contain the raw output data that needs format conversion and processing
      - name: Download Terraform Output Artifacts
        uses: actions/download-artifact@v4
        with:
          # === ARTIFACT DOWNLOAD CONFIGURATION ===
          # Retrieve artifacts generated by the terraform-output job
          # Artifacts are stored in a dedicated directory for organized processing
          name: terraform-output-${{ github.event.inputs.configuration }}-default    # Match artifact name from reusable workflow
          path: terraform-artifacts/         # Organized directory for artifact storage
      
      # === TERRAFORM OUTPUT VALIDATION AND PREPARATION ===
      # Validate downloaded artifacts and prepare processing environment
      # This step ensures data integrity and sets up variables for subsequent processing
      - name: Validate and Prepare Terraform Output
        id: validate-output
        shell: bash
        run: |
          echo "::notice title=Validation Start::üîÑ Starting Terraform output validation and preparation..."
          
          # === PROCESSING CONTEXT SETUP ===
          # Extract configuration and processing parameters from workflow inputs
          # These parameters control output format, metadata inclusion, and file naming
          config="${{ github.event.inputs.configuration }}"
          export_format="${{ github.event.inputs.export_format }}"
          include_metadata="${{ github.event.inputs.include_metadata }}"
          
          echo "::notice title=Processing Context::‚öôÔ∏è Configuration details:"
          echo "::notice::‚Ä¢ Configuration: $config"
          echo "::notice::‚Ä¢ Export format: $export_format" 
          echo "::notice::‚Ä¢ Include metadata: $include_metadata"
          echo "::notice::‚Ä¢ Timestamp: $(date -u +"%Y-%m-%dT%H:%M:%SZ")"
          
          # === TERRAFORM OUTPUT VALIDATION ===
          # Validate the output from the reusable workflow and identify the correct artifact file
          # Support multiple artifact formats (JSON preferred, text as fallback)
          tf_output_status='${{ needs.terraform-output.outputs.terraform-output }}'
          echo "::debug::Terraform output status from reusable workflow: $tf_output_status"
          
          # === ARTIFACT FILE DISCOVERY ===
          # Locate the appropriate artifact file with preference for JSON format
          # JSON artifacts provide structured data optimal for processing and conversion
          if [ -f "terraform-artifacts/terraform-output-artifact.json" ]; then
            artifact_file="terraform-artifacts/terraform-output-artifact.json"
            echo "::notice title=Artifact Located::üìÑ Using JSON artifact file for processing"
          elif [ -f "terraform-artifacts/terraform-output-artifact.txt" ]; then
            artifact_file="terraform-artifacts/terraform-output-artifact.txt"
            echo "::notice title=Artifact Located::üìÑ Using text artifact file for processing"
          else
            echo "::error title=Missing Artifact::‚ùå No Terraform output artifact found in expected locations"
            echo "::debug::Searching for available files in terraform-artifacts directory..."
            ls -la terraform-artifacts/ 2>/dev/null || echo "::error::Terraform artifacts directory not found"
            
            if [ -d "terraform-artifacts" ]; then
              echo "::debug::Available files in terraform-artifacts:"
              find terraform-artifacts -type f -exec echo "  - {}" \;
            fi
            exit 1
          fi
          
          # === FILE SIZE ANALYSIS AND PROCESSING MODE DETERMINATION ===
          # Analyze file size to determine optimal processing strategy
          # Large files (>50MB) require special handling to avoid memory and performance issues
          file_size=$(stat -c%s "$artifact_file" 2>/dev/null || stat -f%z "$artifact_file" 2>/dev/null || echo "0")
          file_size_mb=$((file_size / 1024 / 1024))
          echo "::notice title=File Analysis::üìä Artifact file size: $file_size bytes (${file_size_mb}MB)"
          
          # === FILE CONTENT VALIDATION ===
          # Validate file content and structure before processing
          # Empty files indicate potential issues with Terraform output generation
          if [ ! -s "$artifact_file" ]; then
            echo "::error title=Empty File::‚ùå Terraform output artifact file is empty"
            echo "::error::This may indicate no outputs were defined in the Terraform configuration"
            echo "::error::or an error occurred during output generation"
            exit 1
          fi
          
          # === JSON STRUCTURE VALIDATION FOR JSON ARTIFACTS ===
          # Perform comprehensive JSON validation to ensure data integrity
          # This prevents downstream processing errors and ensures reliable output parsing
          if [[ "$artifact_file" == *.json ]]; then
            if ! jq empty "$artifact_file" 2>/dev/null; then
              echo "::error title=JSON Validation Failed::‚ùå Invalid JSON structure in artifact"
              echo "::error::Please ensure 'terraform output -json' was used to generate the artifact"
              exit 1
            fi
            
            output_count=$(jq -r 'length' "$artifact_file")
            if [ "$output_count" = "0" ]; then
              echo "::notice title=Empty Output::üìÑ Configuration has no outputs defined"
            else
              echo "::notice title=Valid Output::üìã Found $output_count output definition(s)"
            fi
          else
            echo "::notice title=Text Output::üìã Processing text format artifact"
          fi
          
          # === SETUP OUTPUT DIRECTORY ===
          # Create centralized output directory for organized artifact storage
          # This ensures consistent file organization across all configurations
          mkdir -p "configurations/outputs"
          timestamp=$(date +%Y%m%d-%H%M%S)
          
          # === ENVIRONMENT VARIABLE STORAGE ===
          # Store processing variables for subsequent steps using GitHub Actions environment
          # This approach maintains data consistency across workflow steps
          echo "ARTIFACT_FILE=$artifact_file" >> $GITHUB_ENV
          echo "CONFIG_NAME=$config" >> $GITHUB_ENV
          echo "EXPORT_FORMAT=$export_format" >> $GITHUB_ENV
          echo "INCLUDE_METADATA=$include_metadata" >> $GITHUB_ENV
          echo "FILE_SIZE_MB=$file_size_mb" >> $GITHUB_ENV
          echo "TIMESTAMP=$timestamp" >> $GITHUB_ENV
          
          echo "::notice title=Validation Complete::‚úÖ Artifact validation completed successfully"
      
      # === OUTPUT PROCESSING AND FORMAT CONVERSION ===
      # Process the validated output into the requested format with optional metadata
      # METADATA APPROACH: Leverage operation-metadata output from reusable-terraform-base workflow
      # This eliminates duplication and ensures consistency across all Terraform workflows
      - name: Process and Format Terraform Output
        id: process-output
        shell: bash
        run: |
          echo "::notice title=Output Processing::üîÑ Starting format conversion and processing..."
          
          # === LOAD ENVIRONMENT VARIABLES FROM PREVIOUS STEP ===
          # Retrieve processing parameters stored by the validation step
          artifact_file="$ARTIFACT_FILE"
          config="$CONFIG_NAME"
          export_format="$EXPORT_FORMAT"
          include_metadata="$INCLUDE_METADATA"
          file_size_mb="$FILE_SIZE_MB"
          timestamp="$TIMESTAMP"
          
          # === PROCESSING MODE CONFIGURATION ===
          LARGE_FILE_THRESHOLD_MB=50
          
          # === OUTPUT FILE GENERATION ===
          # Use consistent filename with configuration context for Git-tracked changes
          # Store in centralized outputs directory for simplified access
          output_filename="terraform-output-$config.$export_format"
          output_path="configurations/$config/$output_filename"
          
          # === METADATA INTEGRATION FROM REUSABLE WORKFLOW ===
          # Leverage existing metadata from reusable-terraform-base workflow
          # This ensures consistency with other workflows and avoids duplication
          operation_metadata='${{ needs.terraform-output.outputs.operation-metadata }}'
          
          # === FORMAT-SPECIFIC PROCESSING ===
          if [ "$export_format" = "json" ]; then
            if [ "$include_metadata" = "true" ]; then
              # JSON with comprehensive metadata from reusable workflow
              temp_combined_metadata=$(mktemp)
              
              # === MERGE OPERATION METADATA WITH OUTPUT-SPECIFIC CONTEXT ===
              # Combine reusable workflow metadata with terraform-output specific details
              echo "$operation_metadata" | jq --arg export_format "$export_format" \
                --arg processing_workflow "terraform-output" \
                --arg output_filename "$output_filename" \
                '. + {
                  "output_processing": {
                    "export_format": $export_format,
                    "processing_workflow": $processing_workflow,
                    "output_filename": $output_filename,
                    "file_size_mb": '$file_size_mb'
                  }
                }' > "$temp_combined_metadata"
              
              # === CREATE FINAL OUTPUT WITH MERGED METADATA ===
              # Structure: { "metadata": {...}, "terraform_output": {...} }
              jq -s --argjson metadata "$(cat "$temp_combined_metadata")" \
                '{"metadata": $metadata, "terraform_output": .[0]}' "$artifact_file" > "$output_path"
              rm "$temp_combined_metadata"
            else
              # Clean JSON output without metadata
              jq '.' "$artifact_file" > "$output_path"
            fi
          else
            # YAML format processing
            if [ "$include_metadata" = "true" ]; then
              # YAML with comprehensive metadata from reusable workflow
              temp_combined_metadata=$(mktemp)
              
              # === MERGE OPERATION METADATA WITH OUTPUT-SPECIFIC CONTEXT ===
              # Combine reusable workflow metadata with terraform-output specific details
              echo "$operation_metadata" | jq --arg export_format "$export_format" \
                --arg processing_workflow "terraform-output" \
                --arg output_filename "$output_filename" \
                '. + {
                  "output_processing": {
                    "export_format": $export_format,
                    "processing_workflow": $processing_workflow,
                    "output_filename": $output_filename,
                    "file_size_mb": '$file_size_mb'
                  }
                }' > "$temp_combined_metadata"
              
              # === CREATE FINAL YAML OUTPUT WITH MERGED METADATA ===
              # Structure: { "metadata": {...}, "terraform_output": {...} }
              jq -s --argjson metadata "$(cat "$temp_combined_metadata")" \
                '{"metadata": $metadata, "terraform_output": .[0]}' "$artifact_file" | yq eval -P '.' > "$output_path"
              rm "$temp_combined_metadata"
            else
              # Clean YAML output without metadata
              jq '.' "$artifact_file" | yq eval -P '.' > "$output_path"
            fi
          fi
          
          # === SET OUTPUTS ===
          echo "configuration=$config" >> $GITHUB_OUTPUT
          echo "output-filename=$output_filename" >> $GITHUB_OUTPUT
          echo "output-path=$output_path" >> $GITHUB_OUTPUT
          echo "export-format=$export_format" >> $GITHUB_OUTPUT
          echo "file-size-mb=$file_size_mb" >> $GITHUB_OUTPUT
          echo "include-metadata=$include_metadata" >> $GITHUB_OUTPUT
          
          echo "::notice title=Processing Complete::‚úÖ Output processing completed successfully"
      
      # === REPOSITORY INTEGRATION AND VERSION CONTROL ===
      # Commit generated output files to repository for version control and persistence
      # This ensures processed outputs are available for future workflows and manual access
      - name: Commit Generated Output Files
        run: |
          # === INPUT PARAMETER EXTRACTION ===
          # Extract essential parameters from workflow inputs and previous step outputs
          config="${{ github.event.inputs.configuration }}"
          output_filename="${{ steps.process-output.outputs.output-filename }}"
          export_format="${{ github.event.inputs.export_format }}"
          include_metadata="${{ github.event.inputs.include_metadata }}"
          
          echo "::notice title=Git Integration::üìù Preparing to commit generated output files"
          echo "::notice title=Configuration::‚öôÔ∏è Config: $config, Format: $export_format, Metadata: $include_metadata"
          
          # === GIT CONFIGURATION FOR AUTOMATED COMMITS ===
          # Configure Git identity for automated commits from GitHub Actions
          # Uses GitHub Actions bot identity for clear audit trail
          echo "::notice title=Git Config::üîß Configuring Git identity for automated commits"
          git config user.name "GitHub Actions Bot"
          git config user.email "actions@github.com"
          
          # === OUTPUT FILE DISCOVERY AND STAGING ===
          # Identify and stage all generated output files for commit
          # Includes both standard outputs and potential archive files for large datasets
          echo "::notice title=File Staging::üìÅ Discovering and staging generated output files"
          
          output_files_staged=0
          if [ -f "configurations/$config/$output_filename" ]; then
            git add "configurations/$config/$output_filename"
            output_files_staged=$((output_files_staged + 1))
            echo "::notice title=File Staged::üìÑ Primary output: $output_filename"
          fi
          
          # === ARCHIVE FILE STAGING (FOR LARGE FILE PROCESSING) ===
          # Stage archive file if it exists from large file processing
          archive_filename="${{ steps.process-output.outputs.archive-filename }}"
          if [ -n "$archive_filename" ] && [ -f "configurations/$config/$archive_filename" ]; then
            git add "configurations/$config/$archive_filename"
            output_files_staged=$((output_files_staged + 1))
            echo "::notice title=Archive Staged::üì¶ Archive file: $archive_filename"
          fi
          
          echo "::notice title=Staging Complete::üìä Staged $output_files_staged file(s) for commit"
          
          # === COMMIT OPERATION WITH COMPREHENSIVE METADATA ===
          # Create detailed commit with comprehensive metadata for audit trail and operational visibility
          if ! git diff --cached --quiet; then
            echo "::notice title=Commit Creation::üíæ Creating commit with comprehensive metadata"
            
            # === PROCESSING MODE DETERMINATION FOR COMMIT MESSAGE ===
            # Determine processing mode for accurate commit message generation
            is_summary="${{ steps.process-output.outputs.output-is-summary }}"
            processing_mode=$([ "$is_summary" = "true" ] && echo "summary" || echo "standard")
            
            # === EXTRACT TERRAFORM METADATA FOR COMMIT MESSAGE ===
            # Include Terraform operation details from reusable workflow in commit
            operation_metadata='${{ needs.terraform-output.outputs.operation-metadata }}'
            if [ -n "$operation_metadata" ] && [ "$operation_metadata" != "null" ]; then
              terraform_version=$(echo "$operation_metadata" | jq -r '.terraform_version // "unknown"')
              execution_duration=$(echo "$operation_metadata" | jq -r '.execution_duration // "unknown"')
            else
              terraform_version="unknown"
              execution_duration="unknown"
            fi
            
            # === COMPREHENSIVE COMMIT MESSAGE GENERATION ===
            # Create structured commit message with full context and metadata
            git commit -m "feat(terraform-output): generate $export_format output for $config configuration

          üìä Processing Details:
          ‚Ä¢ Configuration: $config
          ‚Ä¢ Output File: $output_filename
          ‚Ä¢ Export Format: $export_format
          ‚Ä¢ Processing Mode: $processing_mode
          ‚Ä¢ Metadata Included: $include_metadata
          ‚Ä¢ Workflow Run: ${{ github.run_number }}
          ‚Ä¢ Generated By: ${{ github.actor }}
          
          üîß Technical Context:
          ‚Ä¢ Repository: ${{ github.repository }}
          ‚Ä¢ Branch: ${{ github.ref }}
          ‚Ä¢ Commit SHA: ${{ github.sha }}
          ‚Ä¢ Workflow: terraform-output
          ‚Ä¢ Terraform Version: $terraform_version
          ‚Ä¢ Execution Duration: $execution_duration
          ‚Ä¢ Generated At: $(date -u +"%Y-%m-%dT%H:%M:%SZ")
          
          üìã File Information:
          ‚Ä¢ Output Files: $output_files_staged file(s) generated
          ‚Ä¢ Processing Mode: $processing_mode processing applied
          ‚Ä¢ Archive Created: $([ "$is_summary" = "true" ] && echo "Yes (large file)" || echo "No")
          
          üéØ Purpose:
          This output was generated automatically by the Terraform Output workflow
          for infrastructure discovery, migration analysis, and operational visibility.
          
          Generated at: $(date -u +"%Y-%m-%dT%H:%M:%SZ") by workflow run ${{ github.run_number }}"
            
            # === REPOSITORY UPDATE ===
            # Push changes to repository with error handling
            echo "::notice title=Repository Push::üöÄ Pushing changes to remote repository"
            git push origin main
            
            echo "::notice title=Commit Success::‚úÖ Output files committed and pushed successfully"
            echo "::notice title=Commit Summary::üìä Committed $output_files_staged file(s) for configuration: $config"
          else
            # === NO CHANGES DETECTED ===
            # Handle case where no new files were generated (normal for some configurations)
            echo "::notice title=No Changes::‚ÑπÔ∏è No new output files to commit - existing outputs are current"
            echo "::notice title=Status::üìä Repository state unchanged - no action required"
          fi

  # === EXECUTION SUMMARY GENERATION ===
  # Leverage standardized reusable workflow for consistent execution reporting
  # Provides comprehensive summary with troubleshooting guidance and artifact information
  execution-summary:
    name: "üéØ Execution Summary"
    needs: [terraform-output, process-and-commit]
    uses: ./.github/workflows/reusable-execution-summary.yml
    if: always()
    with:
      # === CORE WORKFLOW IDENTIFICATION ===
      workflow-name: "terraform-output"
      operation-type: "output"
      configuration: ${{ github.event.inputs.configuration }}
      output-filename: ${{ steps.process-output.outputs.output-filename }}
      
      # === EXECUTION CONTEXT ===
      job-results: ${{ toJSON(needs) }}
      workflow-inputs: ${{ toJSON(inputs) }}
      
      # === SUMMARY CUSTOMIZATION ===
      include-troubleshooting: true
      include-technical-details: true
      summary-level: "detailed"
      
      # === ARTIFACT CONFIGURATION ===
      artifact-retention-days: 30
